

```python
import tensorflow as tf
```

#### 1. 在上下文管理器“foo”中创建变量“v”。


```python
with tf.variable_scope("foo"):
    v = tf.get_variable("v", [1], initializer=tf.constant_initializer(1.0))
                        
#with tf.variable_scope("foo"):
   # v = tf.get_variable("v", [1])
    
with tf.variable_scope("foo", reuse=True):
    v1 = tf.get_variable("v", [1])
print (v == v1)

#with tf.variable_scope("bar", reuse=True):
   # v = tf.get_variable("v", [1])
```

    True


#### 2. 嵌套上下文管理器中的reuse参数的使用。


```python
with tf.variable_scope("root"):
    print tf.get_variable_scope().reuse
    
    with tf.variable_scope("foo", reuse=True):
        print tf.get_variable_scope().reuse
        
        with tf.variable_scope("bar"):
            print tf.get_variable_scope().reuse   #- 某个外层嵌套层设置了reuse为true, 内层仍然为true -#
            
    print tf.get_variable_scope().reuse
```

    False
    True
    True
    False


#### 3. 通过variable_scope来管理变量。


```python
v1 = tf.get_variable("v", [1])
print (v1.name)
```

    v:0



```python
with tf.variable_scope("foo",reuse=True):
    v2 = tf.get_variable("v", [1])
print (v2.name)
```

    foo/v:0



```python
with tf.variable_scope("foo"):
    with tf.variable_scope("bar"):
        v3 = tf.get_variable("v", [1])
        print (v3.name)
```

    foo/bar/v:0



```python
v4 = tf.get_variable("v1", [1])
print (v4.name)
```

    v1:0


#### 4. 我们可以通过变量的名称来获取变量。


```python
with tf.variable_scope("",reuse=True):   
    v5 = tf.get_variable("foo/bar/v", [1])
    print (v5 == v3)
    v6 = tf.get_variable("v1", [1])  #-""表示不指定,变量名称,然后设置reuse=True,就可以获取"v1",如果在最外层获取"v1"会报错-#
    print (v6 == v4)
```

    True
    True


##------实验--------##


```python
a = tf.get_variable('a1', shape=[1])
```


```python
print(a)
```

    <tf.Variable 'a1:0' shape=(1,) dtype=float32_ref>



```python
#- 会报错, 重复定义, 但是没有指定reuse=True
a_1 = tf.get_variable('a1')
```


```python
#- 必须指定reuse=True
with tf.variable_scope('', reuse=True):
    a1 = tf.get_variable('a1')
    print(a1 == a)
```

    True


总结: 用get_variable('name', shape=[])定义的variable, 如果要重复get这个variable, 必须指定reuse=True.


```python
#-当指定了reuse=True时, 只能获取'abc'中已经存在的变量,否则将会报错: 'a2' is not exist.
with tf.variable_scope('abc', reuse=True):
    a1 = tf.get_variable('a2', [1])
    print(a1)
```


```python
#-reuse为False时,如果获取'abc'中不存在的变量,将会创建新的变量.
with tf.variable_scope('abc'):
    a1 = tf.get_variable('a2', [1])
    print(a1)
```

    <tf.Variable 'abc/a2:0' shape=(1,) dtype=float32_ref>



```python
#使用嵌套scope定义
with tf.variable_scope('layer1'):
    with tf.variable_scope('layer2'):
        a2 = tf.get_variable('a2', [1])
        print(a2)
```

    <tf.Variable 'layer1/layer2/a2:0' shape=(1,) dtype=float32_ref>



```python
#-只指定最内层上下文管理器(variable_scope),获取variable的时候将会报错.
with tf.variable_scope('layer2', reuse=True):
    a2 = tf.get_variable('a2')
    print(a2)  #Variable layer2/a2 does not exist
```


```python
#嵌套定义的variable, 只能把所有层都指定, 才能获取.
with tf.variable_scope('layer1'):
    with tf.variable_scope('layer2', reuse=True): ##指定外层或内层reuse=True, 内层的reuse都是True
        a3 = tf.get_variable('a2')
        print(a3)
```

    <tf.Variable 'layer1/layer2/a2:0' shape=(1,) dtype=float32_ref>

