# 机器学习面试常见问题

[TOC]

# 牛客网2018秋招算法面经汇总

[牛客网2018秋招算法面经汇总 牛客加精贴](https://www.nowcoder.com/discuss/32008)

[面啥挂啥的算法、机器学习岗面经（大量文字） 牛客加精贴](https://www.nowcoder.com/discuss/36815)



# 腾讯:

## 案例1:

https://www.nowcoder.com/discuss/79407

**一面：**  

-  自我介绍。 
- 学习方法。 
- 项目。 
- 对比adaboost，随机森林，gbdt，xgb。 
- 场景题：有高德地图的全部权限，怎么预测道路拥堵情况。 
- 智力题：很多很多球，不一样大，A先拿10个，B再拿20个，问A的最大的球比B的最大的球大的概率.   [1/3]

  **二面：**  

- 自我介绍。 
- 学习方法（tx真的很喜欢问这个，不知道为啥）。 
- 熟悉什么模型。 
- 熟悉决策树啊，那讲讲怎么生成和剪枝。 
- 凸优化了解哪些？讲一下原理。 
- 推荐系统了解多少？讲讲原理。 
- 项目。

**自己的不足的总结:**

- 对比adaboost, randomforest, gbdt, xgb.
- 学习方法
- 凸优化
- 推荐系统
- 项目
- 自我介绍



# 美团点评

## 案例1 偏图像的算法岗

https://www.nowcoder.com/discuss/79207

**一面:**

- 自我介绍
- 项目
- faster-rcnn, vgg-16网络结构, rpn
- 手写一个最大连续子数组的长度.

**二面**:

- 问项目, 归一化的一些问题
- 手推bp网络
- 跳台阶, 一次只能挑3阶或2阶, n个台阶几种跳法. 递归写法被鄙视, 改成循环写法才通过.
- 跳台阶升级版, 一次可以跳1到n次, n个台阶几种跳法. 解法1:递推公式; 解法2:排列组合写法.
- 推到fibonacci数列的通项公式.
- 问了海量数据查询的问题.



## 案例2 春季实习面试

https://www.nowcoder.com/discuss/75787

一面**:

- 项目 细节创新 到整体架构 15分钟
- GBDT原理 常用的调参的参数
- xgboost跟GBDT比优点都有哪些
- 一道SQL题 count(1), count(*), count(列名)这三个有什么区别



**二面**:

- L1和L2正则化区别

- Xgboost中的行抽样, 可以起到哪些作用, 样本少了不是会过拟合, 为什么行抽样可以防止过拟合?

  ```
  这个是xgb借鉴了随机森林思想的提现，可以参考bagging思想，对于单颗树而言会确实会过拟合，但是对于整体会减少过拟合
  ```

- 一个数组,找出第k大的数, 时间复杂度



## 案例3 应该是17秋招

**一面:** 40min

```
1、    总的来说，美团的面试官还是很好的，循循善诱，技术不是太差的话，应该都能过
2、    介绍了实习项目，数据特征怎样选择的？怎样表示的？模型的选择？当时的模型参数是多少？结果效果如何？
3、    RF与GBDT的区别？为啥你要用集成的方法而不用准确度更高的算法模型？
4、    推导LR
5、    编程题：删除链表中倒数第K个节点，写出来后，面试官加难度：如果是个带环的链表呢？也就是先找到环的入口，再注意边界条件就行
6、    有什么问我的么？我们是风控部门，主要涉及资金、账号安全，作弊，刷单，反爬虫等
```

**二面: 30min**

```
1、    纳尼？！美女面试官！秋招期间碰到的唯一一个女的算法面试官，还是美女。。。。
2、    介绍实验室项目，交流下预测那里怎么做的
3、    为啥LR的输入特征一般是离散的而不是连续的？
4、    了解各种优化算法不？梯度下降和随机梯度下降的区别？牛顿法和拟牛顿法的区别？为啥提出拟牛顿？因为牛顿法涉及海塞矩阵，它的逆矩阵求解很麻烦
5、    KNN的使用场景
6、    智力题：
1<=a,b<=99，甲手里有a+b的结果，乙手里有a*b的值，两人目前都不知道a和b的值，两人对话如下：
1甲：你肯定不知道a，b的值是多少
2乙：我好像知道了
3甲：我好像也知道了
问：a，b的值是多少
思路：对话1说明a+b的可能性有多种组合，其对应的乘积也有多种组合，形成两个集合S和T
对话2说明乙根据手里的乘积结果，可以得出S和T这两个集合的交集是唯一的
对话3说明甲猜到了乙的想法，故也能猜出交集唯一。。。
```

**三面 30min**

```
1、    这个面试官貌似是一总监或者技术经理
2、    介绍实习项目，和上面的类似
3、    项目期间遇到的问题以及怎么解决的？
4、    从数学角度和你的个人理解完整推导和讲解LR
5、    又仔细讲了下风控部门的主要业务，
```

## 案例4

https://www.nowcoder.com/discuss/36432

 人生第一次比较专业的技术电话面试，之前都是现场面感觉不慌，反而电话面试慌了，下面给大家发点福利 

  1.个人介绍 

  2.java,c/c++,数据结构与算法掌握情况，介绍一下常见的排序算法，讲一下原理 

  3.讲一下令你印象最深的项目，主要讲了KPI指标的设计 

  4.讲一下竞赛的过程，数据如何处理的以及特征工程的构建，用到的机器学习算法, 

  5.然后接着一连串的机器学习算法问题(xgboost，rf，GBDT三者的区别，以及带来模型的提升多大，为什么不采用其他方法，是否比较过这三者的应用场景） 

  6.线性回归与LR的原理与区别，LR的损失函数，以及为什么采用sigmod函数 

  7.svm的原理以及对偶问题，为什么采用对偶，解释一下对偶 

  8.三种决策树的分裂标准，决策树停止生成的条件，如何防止过拟合 

  9.过拟合的常见方法 

  10.boosting和bagging的原理与区别，常见的代表有哪些 

  11.讲一下AUC，在什么情况下采用AUC值，以及召回率与准确率，如何选择合适的评价指标 

  12.下面写个算法吧，连续子数组的最大和



## 案例5

```
作者：艾尼尔克
链接：https://www.nowcoder.com/discuss/44421
来源：牛客网

美团 机器学习
   走进去的时候 面试官对着简历反复看了好几遍 感觉没有兴趣点 ，隐隐约约的觉得马上要GG了
   1  问了 卷积层和池化层的区别  
            卷积层：用它来进行特征提取。
            池化层：对输入的特征图进行压缩，一方面使特征图变小，简化网络计算复杂度；一方面进行特征压缩，提取主要特征


     2  卷积公式 手写  撸了一个二维的卷积 ，一维的忘了
        /f(t)g(x-t)dt  /表示积分
        
    3你对传统的机器学习有了解吗？比如？
            
 4哦  逻辑斯地回归  说一下目标函数 （ 说了对数损失）
   5 为什么用这个目标函数 
    6 平方误差可以用在这个损失函数上吗？ 为啥？
           （ 说平方误差不好 ，解释了为啥  问能用吗？ 我想回去看统计学习了）
    7 你的研究课题是啥？ 懵逼中 ，你做了啥？（。。。）
    8 大数据    
        （没深入）
 9 输入正整数N 打印2^ n值
        首先说移位，然后大数怎么办 ？最后算法没写出来。
GG
   
 总结： 传统的机器学习方法有待提升 ，需要看大数据的东西     
```



# 腾讯

## 案例1 博士 腾讯提前批实习面试

**一面:**

- 凸优化了解吗? 传统机器学习了解吗? 

```
机器学习基本知识都学过, 凸优化只了解和机器学习优化算法相关的.
```

- 编程题: 打印所有子集

**二面:**

- 编程题: 打印螺旋矩阵
- Linux里面查看端口被占用的命令
- AUC是什么
- LR和SVM的区别.



## 案例2 现场面 腾讯新闻应用研究

- 非递归形式求树的深度
- 问项目的东西, 问得很细
- xgb基本原理

```
XGB比GBDT多利用二阶导和正则化, 厉害了,竟然可以推到XGB
```

- 推到LR
- XGB一共用了几颗树
- 简历上写了深度学习,就问了lstm结构, 大概讲了讲, 然后画了结构图
- 深度学习模型的应用场景.

一面挂.



## 案例2 博士实习面试

**线下笔试:**

- 机器学习岗考的都是数学. 在牛客网上随便刷了刷题, 回忆了一下知识. 统计部分的都忘记了

**一面**:

- 聊论文
- 深度学习的了解程度, 手写BP算法. 伪代码写
- LR和Boost的区别:

```
先是细说了LR是什么，怎么推导来的，然后说Boost是什么，干什么用，以Adaboost和GDBT简单举例，最后说二者联系和区别。 
```

- LR/Boost和朴素贝叶斯的区别: 答了生成模型和判别模型的区别
- 编程题:
  -  翻转链表前K个.
  - 覆盖字符串所有字符的最小子串. Leetcode第76题.

**二面**:

- 编程题: 0-1矩阵中, 全1矩阵的最大矩形面积.  Leetcode-85
- poi最近的几个..



# 网易

## 案例1 网易游戏人工智能研发工程师

https://www.nowcoder.com/discuss/75166





# 阿里

## 案例1  算法工程师-机器学习

https://www.nowcoder.com/discuss/75166



## 案例2 菜鸟机器学习一面 春季

https://www.nowcoder.com/discuss/70004

1.自我介绍

2.文章，为什么这么做，怎么想到的？   很厉害。。

3.介绍一下你现在主要的研究方向和兴趣

4.说一下自己的比赛，巴拉巴拉说了一堆，其中关于后处理的问题，他表示很感兴趣。。

5.说一下Xgboost原理，为什么好？

6.开放性问题，菜鸟无人仓机器人从A到B，需要100个机器人到达，怎么样效率最高

8.最后，你有什么想问的吗？



# 链家

## 案例1 春招机器学习岗

**一面**:

- 项目介绍
- 贝叶斯定理的理解, 给出一个实际的例子, 计算后验概率
- DFS和BFS的区别
- 如何读取python命令行函数的参数
- 几个排序算法的时间复杂度



**二面:**

- 完全聊项目
- 特征处理
- 为什么进行离散化
- 为啥选这个模型



**技术面:**

- L1和L2的区别
- kmeans的k的值怎么调
- 谱聚类的整体过程, 拉普拉斯矩阵的第二个小的特征向量叫什么
- LDA主题模型, 是否了解吉布斯采样
- 对VC维的理解
- 项目中如何一步一步解决遇到的实际问题
- 编程题: 有一个普通的二叉树，每个节点有个int值，求从根节点到叶子节点的和最小的路径 



## 案例2 

**一面:**

```
作者：明日韭菜
链接：https://www.nowcoder.com/discuss/61907
来源：牛客网

1、    面试前全体做五道编程题：
1数组中出现次数超过一半的数
2括号匹配
3一串珠不同颜色，求包含所有颜色的最短子串
4从日志中找出IP出现次数超过1024次的恶意IP
2、    最小二乘与极大似然函数的关系？从概率统计的角度处理线性回归并在似然概率为高斯函数的假设下同最小二乘简历了联系
3、    LR为啥是个线性模型？本质就是线性的，只是特征到结果映射用的是sigmoid函数，或者说回归边界是线性的，即P(Y=1|x)=P(Y=0|x)时有W*x=0
4、    Hadoop中MR是怎么实现联表查询的？
5、    分类的评价标准，准确度，AUC，召回率等等
6、    有的逻辑回归损失函数中为啥要加-1*m
7、    欠拟合的解决方法？模型简单，加深神经网络，svm用核函数等等
8、    L2正则的本质？限制解空间范围，缩小解空间，控制模型复杂度
9、    SVM引入核函数本质？提高维度，增加模型复杂度
```



# 便利蜂

## 案例1

链接：https://www.nowcoder.com/discuss/61907

**一面**:

```
1、问实习项目
2、特征工程做的有哪些？非线性可分的情况怎么处理的？
3、SVM的核函数了解多少？
4、L1与L2区别？L1为啥具有稀疏性？
5、xgboost的原理
6、sigmoid函数的导函数的取值范围是多少？其实就是一元二次方程的y值范围，0-1/4
```

**二面:**

```
1、    实习内容：数据之间的关系和特征？
2、    Python中协成的概念，即微线程，具体可以看廖雪峰的网站
3、    C++中vector增删改的时间复杂度，O(1)，O(n)，O(n)
4、    MySQL中索引用的什么数据结构？B-Tree或B+Tree
5、    Hash_table的底层是什么实现的？拉链法，数组+链表
6、    HBase的列式存储解释
7、    面试官建议多注重工程方面的能力，全程不问机器学习方面的问题
```



# 滴滴

## 案例1

**一面:**

```
1、    介绍实验室的项目
2、    介绍xgboost、gbdt、rf的区别
3、    树模型的特征选择中除了信息增益、信息增益比、基尼指数这三个外，还有哪些？
4、    Sklearn中树模型输出的特征重要程度是本身的还是百分比？
5、    介绍下SVM以及它的核函数
6、    熟悉FM算法不？
7、    算法题：两个链表的第一个公共节点
```

**二面:**

```
1、    面试官一直看时间，感觉就是为了走个过场
2、    介绍下实验室项目
3、    进程和线程的区别？
4、    HBase数据库的优点？
5、    闲聊。。。你想从事哪方面的算法？c++用了几年？有啥问我的吗？我是做路径优化的
```

## 案例2

https://www.nowcoder.com/discuss/54238

 **滴滴内推：** 

  **一面：**

  1.算法：最长不重复子序列（leetcode原题）； 

  2.然后介绍自己的项目，中间问了些问题； 

  3.推导逻辑回归

  3.也许代码很快，所以一面基本就这么过了。。。。 

  **二面：** 

  二面比较坑，面试官着急走，问的问题很快，有些我还一直懵逼状态 

  1.有种场景，利用规则算法有着不错的效果，可是利用规则之后的结果输入到模型中，为什么结果还变差了？ 

  2.长尾数据如何处理？ 

  3.GBDT在什么情况下比逻辑回归算法要差？ 

  4.GBDT对输入数据有什么要求，如果效果比较差，可能是什么原因造成的？ 

  5.DP，edit sitance 问题 

  6.比较下逻辑回归与GBDT



**滴滴校招：** 

  **一面：** 

  1.算法，有点醉，和之前内推的题目是一模一样的，又是最长不重复子序列，秒解。。 

  2.sigmoid函数可以优化梯度消失的问题么，数学问题，自己推导公式看下 

  3.sigmoid函数求导，与问题2有关 

  4.神经网络非线性原因分析 

  5.推导逻辑回归。。。。是的，又推导了 

  6.聊项目 

  7.hadoop与spark比较 

  8.如何理解spark是基于内存的

  9.JAVA多线程问题 

  10.SVM核函数理解，线性回归如何利用核函数，有什么弊端 

  11.笔试成绩不错，说说笔试编程题。。。。。有点醉，不过还好比较简单还记得一点 

  我感觉一面面了快90分钟了。。。。

  **二面：** 

  1.写线性回归损失函数 

  2.写个全排序 

  3.比较下常用的聚类算法，你如何理解在什么场景使用他们 

  4.全排序有重复数字呢？没写，说了思路 

  5.出了两个概率题，题目有点忘了，楼主没有答出来，不过还好之前算法写的还行，这个他也没怎么计较 

  6.机器学习非线性模型以及线性模型解决非线性问题 

  **三面：** 

  1.最短路径算法，问的很深，基本最短路径所有的算法都问了； 

  2.图论中的问题，感觉主要考你的理解能力，最小割问题吧（不确定）解决思路和最小生成树有关，时间长了有点忘了，这题没有参考价值，就是看理解能力； 

  3.问了项目中的一个模型，他问了各种优化思路，我感觉撞枪口了，这个模型的优化他绝壁很熟悉（三面一定要对模型认识比较深刻，最好能有自己的优化想法，能够吹逼）； 

  4.写个DP，01背包问题





# 完美世界

## 案例1 数据开发工程师

https://www.nowcoder.com/discuss/61907

**一面挂:**

```
1、    两个面试官，其中一个主要负责问
2、    介绍实习项目，怎么判断特征的重要性？rf与gbdt的区别讲下？
3、    对实验室的项目丝毫不感兴趣，面试官果然不是做算法的。。。
4、    算法题：两个数字链表求和，将结果也存到一个链表里面，注意相加超10时进位就行
```



# 苏宁 

## 案例1

```
1、    是一个年龄不小的面试官，貌似经理或者总监
2、    自我介绍+聊实习项目
3、    RF与xgboost的区别？怎样选取的特征？如何判断这些特征的重要程度？最后RF的层数和深度是多少？
4、    还用了深层神经网络？几层？用GPU没？特征维度到底多少？服务器配置？啥？你能把全部数据放进内存？
5、    有啥问我的没？我是搜索部门的，即所有涉及搜索相关的业务。。。
```



# 乐信 

## 案例1

**一面:**

```
1、    自我介绍，介绍实验室项目，发表的论文内容
2、    关联规则中，置信度和支持度的概念？
3、    MySQL中MYISAM和InnoDB的区别
4、    LR，svm，rf等算法的区别
5、    模型评价指标，解释AUC，准确率和召回率
6、    对于同一个数据，怎样根据AUC判断模型的好坏？数据？没听懂。。。
7、    介绍实习的项目，服务器配置
8、    有啥问我的么？我们是大数据部门，数据仓库、分析、算法，涉及各种与金融相关的业务
```



# 新浪门户

## 案例1

**一面:**

```
1、    很严肃的一个面试官，感觉他面试了很多人的样纸，不让自我介绍，有点小傲娇的样纸。。
2、    讨论实验室的项目
3、    介绍LR，为啥用的是似然函数不用最小二乘？当用lr时，特征中的某些值很大，意味着这个特征重要程度很高？对吗？不对，用lr时需要对特征进行离散化。。。
4、    L1和L2正则的区别？
5、    树模型中，特征选择方法有哪些？ID3和C4.5分裂后，节点的信息熵是变大还是变小？变小
6、    RF和gbdt的区别
7、    介绍下深度学习，CNN中的卷积和池化
8、    Hadoop中shuffle过程
9、    有啥问我的么？我是新浪手机客户端部门那儿的，主要做推荐等等
```



# 58到家 

## 案例1

https://www.nowcoder.com/discuss/61907

**58到家(一面，1h)**

```
1、    很年轻的面试官，感觉面试经验不足，大部分时间是我讲。。。
2、    项目期间遇到的问题，怎么解决的？
3、    为啥你的svm训练起来那么慢？
4、    了解贝叶斯不？它的应用场景都有哪些？
5、    知道哪些深度学习的框架？
6、    网络分几层？TCP和UDP区别？写个快排吧
7、    场景题：一个10T的文本，一个10M的文本，从大文本中找出与小文本中相似度大于80%的文本，提示，用SameHash
8、    我们是58速运部门的，主要做路径优化和推荐
```

**58到家(二面，40min)**

```
1、    这个面试官是58家政部门的
2、    同一面，详细介绍了下实习项目，从特征工程到最后的模型融合
3、    场景题：北京市所有小区的客户发出家政请求的可能性(回归问题)；或者从家政的全部业务流程中找出一个具体场景进行分析：家政阿姨接到派单通知后，进行家政服务的路径选择，可阿姨一天顶多服务2-3个家庭，该如何派单？
4、    讨论之前的笔试题编程题：最短回文串，但是题目中有要求只能向字符串的末尾插入字符串，使得新字符串是最短的回文串，不是向任意位置插入。。。
```



# 百度

## 案例1

**一面:**

```
1、    很年轻的面试官，问的很广，感觉回答出来了80%，依然没过
2、    介绍实验室项目，是怎样用的KNN进行的预测
3、    XGBoost与RF的区别
4、    RF的随机性体现在哪里？它的代码中输出的特征重要程度是怎么进行计算的？
5、    实习项目中的评价标准是什么？accuracy和precision、recall这些一样吗？AUC的解释
6、    了解哪些损失函数？区别是啥？
7、    线性模型为何用的最小二乘作为损失函数而不用似然函数或者交叉熵？
8、    了解哪些深度学习模型？keras底层用TensorFlow和theano时，代码有何不同？TensorFlow原理、流程图，session是啥？
9、    编程题：两个数组的最长公共子序列和最长递增子序列，用DP写出来后，让继续优化。。。

```

## 案例2

https://www.nowcoder.com/discuss/44211

**一面**:

- 项目
- 决策树原理, 剪枝
- 一个单词逆序的程序(手写)
- 一些简单的数据结构

**二面**

- 一个动态规划的题
- 归并排序, 两路之间怎么合并(败者树)
- CNN神经网络原理(局部图像信息的关联性)
- 向量的泰勒公式展开(考虑到海森矩阵, 雅可比, 还是没写出来)
- 变分的意思



# 陌陌

## 案例1

**一面**:

```
1、    介绍实验室项目，对问题是回归还是分类进行了详细探讨。。。
2、    LR与SVM的区别
3、    GBDT与XGBoost的区别？
4、    实习期间遇到的问题，是怎么解决的？
5、    了解FM吗？GBDT的数据在使用前有什么需要注意的吗？
6、    做过广告点击率预估没？LR+GBDT和GBDT+FM怎么结合的知道不？
```

**二面**:

```
1、    LR与GBDT的结合了解不
2、    智力算法题(说是它的校招笔试题)：
        f(x)=p,y=0;  1-p,y=1  将这个概率函数转换为T(x)=1/2, y=0或者y=1
       提示：f(x)执行四次可能出现的结果有0,0：p^2        0,1:p*(-1p)         1,0:p*(1-p)          1,1(1-p)^2
      里面有两次结果的概率是一样的
```

HR面重点: 我们发15月, 还有加班费..



# 唯品会

## 案例1 一二面 40 + 20 min

```

1、    一面试官是做java后端开发的，有点尬聊。。
2、    简单介绍下实习项目，解释了rf和gbdt
3、    项目中遇到的问题，怎么解决的？
4、    了解各种大数据框架不？呵呵哒。。。。
5、    二面面试官貌似主管或者经理级别
6、    对公司的业务进行了详细的介绍，并展示了团队在硅谷的人员。。
7、    场景题：如何向小学生推荐或者预测适合的外教？怎样准备数据和算法？
8、    别人二面后直接HR面，我面后，被告知加一面，等待北京算法负责人电面，什么鬼。。。
```



# 京东

## 案例1

https://www.nowcoder.com/discuss/54238

**一面：** 

  1.算法，二分法的扩展版本，leetcode都有，就那4、5道吧； 

  2.算法，快排，我面试的时候隔壁有个广州来的表现不好，冒泡、快排都没写出来，影响了我的面试官，给我出了个简单的； 

  3.hadoop问题，类似二次好友问题，一个key有很多个value，找出内容相近的key（没说多相近），我说了simhash和二次好友两种解决思路

  4.聊项目 

  5,推导你最熟悉的机器学习算法，楼主选了SVM，不想推导逻辑回归了 

  6.说说你对机器学习的看法。。。。这问题厉害了 

  **二面：** 

  1.写代码，一个数组中有一个数字出现两次，找出来 

  2.代码，判断一棵树是不是对称的 

  3.比较随机森林和GBDT，选择一个重点说说 

  4.如果随机森林数的树的个数无穷大，你觉得会过拟合么 

  5.GBDT对异常数值敏感么，GBDT如何处理缺失值 

  6.你是如何处理缺失值和异常值的 

  7.对hadoop和spark了解程度 

  8.能来实习么，觉得自己适合做什么？



# 顺丰科技

## 案例1

https://www.nowcoder.com/discuss/48467

```
1.自我介绍
2.了解哪些算法
3.说说LR和SVM的区别
4.说说项目经历，有什么可以改进的
5.(一个比赛)为什么选择xgboost，有什么优点
6.业务场景，预测用户愿不愿意由纸质订单换为电子订单
7.为什么想做机器学习(答因为曾实现一个单隐层bp算法神经网络，被非线性效果惊讶到)
8.为什么神经网络非线性这么好
9.传统算法怎么实现非线性
10.说论文
11.为什么选择顺丰
```



# 某创业公司

 https://www.nowcoder.com/discuss/51437

创业公司不大，去年刚成立。拉钩上投的简历。本来我是去面试实习生的，但是一面表现不错，后面直接面正式岗了。最后offer的薪资挺高的，而且CTO答应入职后让团队leader做我的导师，感觉自己运气还是很不错的。 

  **一面：** 

  1.介绍项目。 

  2.讲下项目里用到的 决策树。（讲了下决策树的结构，常见的决策树模型） 

  3.讲下CART的分裂结点选择依据。（回归用最小平方和误差，分类用基尼指数） 

  4.决策树怎么避免过拟合。（预剪枝和后剪枝，然后 讲了下两种剪枝的过程） 

  5..介绍下项目里用到的 LSTM模型。（画了下LSTM cell的结构，然后讲了下每层的 激活函数） 

  6.提出LSTM是为了解决什么问题？（梯度消失和梯度爆炸） 

  7.为什么LSTM可以解决梯度问题？（这个问题以前没有想过，现场胡编了一个，说gate分担了 一部分梯度的衰减或者爆炸。后来网上查了下发现，如果很久以前的信息很重要，forget gate的值会接近于1，而hidden state的激活函数是identity function，这样梯度就不会随时间改变） 

  8..手写代码。 

  有序数组旋转，求最小元素位置。（二分，mid和末尾元素对比） 

  青蛙跳n级台阶。给定一个数组，里面包含一步可以跳的台阶数，求跳到n级台阶的最少步数。要求只能刚好跳到n级，跳过了不算。（用动态规划解，开辟一个长度为n+1的一维数组dp，dp[i]代表跳到i级台阶需要的 最少步数。dp[0]初始化为0，其余初始化为-1） 

  还是跳台阶，但是需要输出路径。给出思路。（一开始回答用广度优先遍历，超过n级则剪枝。面试官要求结合之前的 dp解法，想了下，用二维数组，paths[i]表示跳到i级台阶的最少步数对应路径，在动态规划的过程中知道从哪一级台阶j跳到当前台阶i步数最短，就在paths里添加paths[j]+[i]） 

  **二面CTO面：** 

  先随便聊了下。然后手写代码。 

  1.类似“aabbccccdeffg”的字符串转化成“2a2b4cde2fg”的形式。（这个很简单，不说了） 

  2.一张海洋的高空拍摄图，图中有小岛，设计一个算法计算图中独立的小岛个数。上下左右为相接。（用只包含01的二维数组储存图像，蓝色为0，非蓝色为1。遍历数组，用字典存每个坐标的编号，岛屿编号从1开始，海洋点编号0。最大的岛屿标号就是小岛个数。复杂度O(n)） 

  **三面CEO面：** 

  也是先聊了下，然后问几道数学和统计方面的题目。 

  1.最小平方误差求最小值。（求导，令导数等于0） 

  2.求sum(|Xi-w|)最小值。（w等于所有Xi的中位数的时候。方法是画数轴） 

  3.求sum(|wi*Xi-u|)最小值。(加入松弛变量，然后用KKT。类似SVM 软间隔问题求解) 

  4.已知一个均值分布，怎么得到正态分布。（Box-Muller transformation） 

  5.Box-Muller的本质是什么。(转化公式不记得了，这题没答上来)



# 华为

## 案例1 中央软件院 机器学习算法

https://www.nowcoder.com/discuss/32563



# 蘑菇街

## 案例1

```
作者：芒果没有he
链接：https://www.nowcoder.com/discuss/26339
来源：牛客网

二面：
（1）反转一个链表，邻近的奇数节点和偶数节点互换，比如输入{1,2,3,4,5}，要求返回{2,1,4,3,5}，输入{1,2,3,4}，要求返回{2,1,4,3}
（2）谈谈LR的思想，LR对输入和输出的分布假设是什么？
（3）谈谈树
```

